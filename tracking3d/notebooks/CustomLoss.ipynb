{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  8 16:21:12 2017       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 384.90                 Driver Version: 384.90                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 1080    Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8     9W / 180W |    821MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 1080    Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 35%   52C    P2    62W / 180W |   1928MiB /  8114MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 1080    Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 34%   52C    P2    66W / 180W |   1717MiB /  8114MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 1080    Off  | 00000000:07:00.0 Off |                  N/A |\n",
      "| 33%   49C    P2    62W / 180W |   1190MiB /  8114MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 1080    Off  | 00000000:0B:00.0 Off |                  N/A |\n",
      "| 33%   49C    P2    66W / 180W |    906MiB /  8114MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 1080    Off  | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 27%   31C    P8     9W / 180W |   7633MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 1080    Off  | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 27%   29C    P8     9W / 180W |     10MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 1080    Off  | 00000000:0E:00.0 Off |                  N/A |\n",
      "| 27%   28C    P8    10W / 180W |   8030MiB /  8114MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 (0000:04:00.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "### Imports ####################################################################\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GRU\n",
    "from typing import Tuple, Callable, List, Optional, Sequence\n",
    "from tracker import visuals, extractor, utils, metrics\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "Tensor = theano.tensor.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "def construct():\n",
    "    for element in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0,
     1,
     14,
     26
    ]
   },
   "outputs": [],
   "source": [
    "### File Writers ###############################################################\n",
    "def write4d(file, array: np.ndarray) -> None:\n",
    "    for cube in array:\n",
    "        for matrix in cube:\n",
    "            for row in matrix:\n",
    "                for number in row:\n",
    "                    string = \"{0: >6.2f} | \".format(number)\n",
    "                    string = string.replace(\"-0.00\", \"     \")\n",
    "                    string = string.replace( \"0.00\",  \"    \")\n",
    "                    file.write(string)\n",
    "                file.write(\"\\n\")\n",
    "            file.write((\"-\" * 110) + \"\\n\")\n",
    "        file.write((\"=\" * 110) + \"\\n\" + (\"=\" * 110) + \"\\n\")\n",
    "\n",
    "def write3d(file, array: np.ndarray) -> None:\n",
    "    for matrix in array:\n",
    "        for row in matrix:\n",
    "            for number in row:\n",
    "                string = \"{0: >6.2f} | \".format(number)\n",
    "                string = string.replace(\"-0.00\", \"     \")\n",
    "                string = string.replace( \"0.00\",  \"    \")\n",
    "                file.write(string)\n",
    "            file.write(\"\\n\")\n",
    "            file.write((\"-\" * 110) + \"\\n\")\n",
    "        file.write((\"=\" * 110) + \"\\n\" + (\"=\" * 110) + \"\\n\")\n",
    "\n",
    "def write(filename: str, array: np.ndarray) -> None:\n",
    "    with open(filename, \"w\") as file:\n",
    "        if len(array.shape) == 4:\n",
    "            write4d(file, array)\n",
    "        elif len(array.shape) == 3:\n",
    "            write3d(file, array)\n",
    "        else:\n",
    "            file.write(str(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Load in Data ###############################################################\n",
    "order  = [\"phi\", \"r\", \"z\"]\n",
    "frame  = pd.read_csv(\"data/sets/ACTS-MU10-PT1000-T50-PREPARED.gz\")\n",
    "data   = extractor.extract_input(frame, order)\n",
    "matrix = extractor.extract_output(frame, order)\n",
    "input_shape  = data.shape[1:]\n",
    "output_shape = matrix.shape[1:]\n",
    "print(len(data))\n",
    "print(input_shape)\n",
    "print(output_shape)\n",
    "n = 3\n",
    "visuals.display_matrices(data[n], matrix[n], order=order, noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Run this cell if you want all events to have max number of hits ############\n",
    "def regularize_frame(\n",
    "        frame      : pd.DataFrame,\n",
    "        num_layers : int,  # How many layers (hits per track).\n",
    "        num_tracks : int,  # How many tracks per event.\n",
    "        ) -> pd.DataFrame:\n",
    "    regular = []\n",
    "    events = (e for _, e in frame[frame[\"padding\"] == 0].groupby(\"event_id\"))\n",
    "    for event in events:\n",
    "        groups = event.groupby(\"cluster_id\")\n",
    "        tracks = groups.filter(lambda track: num_layers == len(track))\n",
    "        if num_tracks <= len(pd.unique(tracks[\"cluster_id\"])):\n",
    "            ids    = tracks[\"cluster_id\"]\n",
    "            unique = np.sort(pd.unique(ids))\n",
    "            mapped = dict((v, u) for (u, v) in enumerate(unique))\n",
    "            tracks = tracks.assign(cluster_id=ids.map(mapped))\n",
    "            tracks = tracks[tracks[\"cluster_id\"] < num_tracks]\n",
    "            if num_tracks == len(pd.unique(tracks[\"cluster_id\"])):\n",
    "                regular.append(tracks)\n",
    "    return pd.concat(regular)\n",
    "\n",
    "frame  = regularize_frame(frame, 4, 5)\n",
    "data   = extractor.extract_input(frame, order)\n",
    "matrix = extractor.extract_output(frame, order)\n",
    "input_shape  = data.shape[1:]\n",
    "output_shape = matrix.shape[1:]\n",
    "print(input_shape)\n",
    "print(output_shape)\n",
    "n = 0\n",
    "visuals.display_matrices(data[5], matrix[5], order=order, noise=False, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visuals.Plot2D(frame[frame[\"event_id\"] == 0], order).plot(mode=\"xy\", title=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1,
     2,
     16,
     28,
     42,
     53,
     77,
     89,
     102,
     115,
     126,
     144
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### LossFunctionCreator #######################################################\n",
    "class LossFunctionCreator:\n",
    "    def __init__(self,\n",
    "            input_tensor : Tensor,\n",
    "            input_shape  : Tuple,\n",
    "            output_shape : Tuple,\n",
    "            order        : List[str],\n",
    "            ) -> None:\n",
    "        \"\"\" Initialize the instance variables. \"\"\"\n",
    "        self.__name__     = \"LossFunctionCreator\"\n",
    "        self.input_tensor = T.as_tensor_variable(input_tensor)\n",
    "        self.meshgrid     = self.make_meshgrid(output_shape)\n",
    "        self.input_shape  = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.order        = order\n",
    "\n",
    "    def make_meshgrid(self,\n",
    "            shape : Tuple[int, int],\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Create a meshgrid.\n",
    "        Example for shape (3, 5):\n",
    "            [[0, 1, 2, 3, 4],\n",
    "             [0, 1, 2, 3, 4],\n",
    "             [0, 1, 2, 3, 4]]\n",
    "        \"\"\"\n",
    "        return (T.mgrid[0:shape[0], 0:shape[1]][1])\n",
    "    \n",
    "    def regression_loss(self,\n",
    "            y_true : Tensor,\n",
    "            y_pred : Tensor,\n",
    "            ) -> Tensor:\n",
    "        input_tensor = self.input_tensor\n",
    "        tensor = None\n",
    "        for i in range(output_shape[1]):  # For each track...\n",
    "            pred_mask = self.get_track_mask(y_pred, i)\n",
    "            true_mask = self.get_track_mask(y_true, i)\n",
    "            pred_num_hits = pred_mask.sum(-1).sum(-1) + 2  # Avoid Div(0).\n",
    "            true_num_hits = true_mask.sum(-1).sum(-1) + 2  # Avoid Div(0).\n",
    "            pred_masked = pred_mask * input_tensor\n",
    "            true_masked = true_mask * input_tensor\n",
    "            pred_line = self.linear_regression(pred_masked, pred_num_hits)\n",
    "            true_line = self.linear_regression(true_masked, true_num_hits)\n",
    "            diff   = (pred_line - true_line)**2\n",
    "            tensor = diff if tensor is None else tensor + diff\n",
    "        return tensor\n",
    "    \n",
    "    def softmax(self,\n",
    "            tensor     : Tensor,\n",
    "            axis       : Optional[int] = None,\n",
    "            refinement : float = 1,\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Return the softmax of the tensor along the specified axis.\n",
    "        Higher refinement yields sharper, more accurate results, but also\n",
    "        tends to yield NaNs for large tensor values.\n",
    "        \"\"\"\n",
    "        exponent = (refinement * tensor).exp()\n",
    "        return exponent / exponent.sum(axis=axis, keepdims=True)\n",
    "\n",
    "    def softargmax(self,\n",
    "            tensor     : Tensor,\n",
    "            indices    : Tensor,\n",
    "            axis       : Optional[int] = None,\n",
    "            refinement : float = 1,\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Return the argsoftmax of the tensor along the specified axis.\n",
    "        Higher refinement yields sharper, more accurate results, but also\n",
    "        tends to yield NaNs for large tensor values.\n",
    "        \"\"\"\n",
    "        return (self.softmax(tensor, axis, refinement) * indices).sum(axis)\n",
    "    \n",
    "    def get_order_mask(self,\n",
    "            string : str,\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Return a mask such that when output is multiplied by this mask,\n",
    "        only the column corresponding to the *string* category remains.\n",
    "        \"\"\"\n",
    "        mask = np.zeros(len(self.order))\n",
    "        mask[self.order.index(string)] = 1\n",
    "        return T.as_tensor_variable(mask)\n",
    "    \n",
    "    def get_track_mask(self,\n",
    "            output   : Tensor,\n",
    "            track_id : int,\n",
    "            aref     : int = 32,  # Refinement value for softargmax.\n",
    "            mref     : int =  4,  # Refinement value for mask values.\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Retrieve a tensor containing a mask such that if self.tensor_input\n",
    "        was multiplied by the mask, the result would be a tensor containing\n",
    "        the positions of all hits with the specified track_id.\n",
    "        \"\"\"\n",
    "        cats = self.softargmax(output, self.meshgrid, refinement=aref, axis=-1)\n",
    "        fill = T.fill(cats, track_id)\n",
    "        diff = (cats - fill)**2\n",
    "        mask = 1 / (mref * diff).exp()\n",
    "        mask = mask.reshape((*T.shape(mask), 1))\n",
    "        return mask\n",
    "    \n",
    "    def linear_regression(self,\n",
    "            tensor : Tensor,\n",
    "            length : Tensor,\n",
    "            ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given a tensor, and the number of hits within the tensor,\n",
    "        return the two parameters (m, b) of the least squares\n",
    "        regression line with equation f[x] = (m * x) + b.\n",
    "        \"\"\"\n",
    "        e = 2 * K.common.epsilon()  # Epsilon to avoid division by 0.\n",
    "        p = (tensor * self.get_order_mask(\"phi\")).sum(-1)\n",
    "        r = (tensor * self.get_order_mask(\"r\")).sum(-1)  # r values.\n",
    "        z = (tensor * self.get_order_mask(\"z\")).sum(-1)  # z values.\n",
    "        d = (length * (r**2).sum(-1)) - r.sum(-1)**2 + e  # Denominator.\n",
    "        m = (length * (r * z).sum(-1) - r.sum(-1) * z.sum(-1)) / d\n",
    "        b = (z.sum(-1) * (r**2).sum(-1) - r.sum(-1) * (r * z).sum(-1)) / d\n",
    "        return m + b\n",
    "    \n",
    "    def __call__(self) -> Callable[[Tensor, Tensor], Tensor]:\n",
    "        \"\"\" Return a Tensor that measures the loss of a model. \"\"\"\n",
    "        def custom_loss(y_true: Tensor, y_pred: Tensor) -> Tensor:\n",
    "            return self.regression_loss(y_true, y_pred)\n",
    "        return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = T.dtensor3(\"A\")\n",
    "B = T.dtensor3(\"B\")\n",
    "C = T.dtensor3(\"C\")\n",
    "D = LossFunctionCreator(A, input_shape, output_shape, order)()\n",
    "E = D(B, C)\n",
    "F = theano.function([A, B, C], E, on_unused_input='ignore')\n",
    "# print(theano.printing.debugprint(E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positions   = data  [0:4]\n",
    "true_matrix = matrix[0:4]\n",
    "pred_matrix = np.random.rand(*true_matrix.shape)\n",
    "pred_matrix = pred_matrix / pred_matrix.sum(-1, keepdims=True)\n",
    "evaluation = F(positions, true_matrix, pred_matrix).round(2)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visuals.display_matrices(data[0], true_matrix[0], 2, order, 0, 0)\n",
    "visuals.display_matrices(data[0], pred_matrix[0], 2, order, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Define Model ###############################################################\n",
    "input_layer = Input(name=\"Input\", shape=input_shape)\n",
    "model_layer = Dense(name=\"Dense 1\", units=512, activation=\"relu\")(input_layer)\n",
    "model_layer = Dense(name=\"Dense 2\", units=512, activation=\"relu\")(model_layer)\n",
    "model_layer = Dense(name=\"Dense 3\", units=512, activation=\"relu\")(model_layer)\n",
    "output_layer = Dense(name=\"Softmax\", units=output_shape[1],\n",
    "                     activation=\"softmax\", kernel_initializer=\"uniform\"\n",
    "                    )(model_layer)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "loss  = LossFunctionCreator(input_layer, input_shape, output_shape, order)()\n",
    "opt   = keras.optimizers.RMSprop(lr=0.0000001)\n",
    "model.compile(loss=loss, optimizer=opt, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Fit Model ##################################################################\n",
    "histories = model.fit(\n",
    "    data, \n",
    "    matrix, \n",
    "    epochs=64, \n",
    "    batch_size=32,\n",
    "    verbose=2, \n",
    "    validation_data=(data, matrix)\n",
    ")\n",
    "predictions = model.predict(data[0:2])\n",
    "write(\"output.txt\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Graph Loss ################################################################\n",
    "plt.plot(histories.history['loss'])\n",
    "plt.plot(histories.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Graph Accuracy ############################################################\n",
    "plt.plot(histories.history['acc'])\n",
    "plt.plot(histories.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
