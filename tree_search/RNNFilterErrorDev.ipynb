{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing an RNN track filter model with gaussian uncertainty\n",
    "\n",
    "In this notebook I want to play around with the code for making an RNN track filter model which predicts a next hit location and also produces uncertainties on that prediction in the form of a gaussian.\n",
    "\n",
    "Basically, the model should produce both the central values and a covariance matrix.\n",
    "The kind of loss that we want to minimize is then a Gaussian log-likelihood loss:\n",
    "\n",
    "$L(x,y) = \\log{|\\Sigma|} + (y - f(x))^{\\rm T}\\Sigma^{-1}(y-f(x))$\n",
    "\n",
    "I want to use pytorch for now, but unfortunately there is no nice functionality to compute a matrix determinant with autograph auto-differentiation. I can piece one together using stuff I've found online, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select a GPU first\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'\n",
    "cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# External imports\n",
    "import numpy as np\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Magic\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0_2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "To compute the determinant with gradients, we need a cholesky decomposition with gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cholesky(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Cholesky decomposition with gradient. Taken from\n",
    "    https://github.com/t-vi/pytorch-tvmisc/blob/master/misc/gaussian_process_regression_basic.ipynb\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, a):\n",
    "        l = torch.potrf(a, False)\n",
    "        ctx.save_for_backward(l)\n",
    "        return l\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        l, = ctx.saved_variables\n",
    "        # Gradient is l^{-H} @ ((l^{H} @ grad) * (tril(ones)-1/2*eye)) @ l^{-1}\n",
    "        # Ideally, this should use some form of solve triangular instead of inverse...\n",
    "        linv =  l.inverse()\n",
    "        \n",
    "        inner = (torch.tril(torch.mm(l.t(), grad_output)) * \n",
    "                 torch.tril(1.0 - Variable(l.data.new(l.size(1)).fill_(0.5).diag())))\n",
    "        s = torch.mm(linv.t(), torch.mm(inner, linv))\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test determinant calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.1574  0.2672\n",
       " 0.2672  5.8062\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a symmetric positive semi definite matrix\n",
    "x = torch.randn(2, 2)\n",
    "x = torch.mm(x, x.t())\n",
    "v = Variable(x)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842461764812\n",
      "0.842461755804\n",
      "0.842462\n"
     ]
    }
   ],
   "source": [
    "# Compare ways to calculate the determinant\n",
    "print((Cholesky.apply(v).diag().log().sum()*2).exp().data[0])\n",
    "print(np.exp(torch.potrf(x).diag().log().sum()*2))\n",
    "print(np.linalg.det(x.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert model outputs into gaussian parameters\n",
    "\n",
    "For dimension $d$, there will be $d$ mean values and a covariance matrix with $d(d+1) \\over 2$ unique values.\n",
    "\n",
    "That's a total of $d(d+3) \\over 2$ values.\n",
    "\n",
    "Ok, I think this will be the trick:\n",
    "\n",
    "Separate out the means, variances, and covariances from the model outputs right away.\n",
    "Construct the covariance matrix initially with the outer product of the variances.\n",
    "Then the off-diagonal elements will already have the scale factors which can be multiplied by the correlations.\n",
    "Construct the correlation matrix using the triangular indexing stuff above plus identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_outputs(outputs, d):\n",
    "    means = output[:d]\n",
    "    variances = output[d:2*d].exp()\n",
    "    correlations = output[2*d:].tanh()\n",
    "    offdiag_idx = torch.ones(d, d).triu(1).nonzero().t()\n",
    "    # Populate the covariance matrix initially with sqrt(vi*vj)\n",
    "    cov_matrix = torch.mm(variances[:, None], variances[None, :]).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cov_log_determinant(cov):\n",
    "    return Cholesky.apply(cov).diag().log().sum()*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " -1.1518\n",
       " -0.0865\n",
       " [torch.FloatTensor of size 2], Variable containing:\n",
       "  0.4833\n",
       "  1.0233\n",
       " [torch.FloatTensor of size 2], Variable containing:\n",
       "  0.2890\n",
       " [torch.FloatTensor of size 1], Variable containing:\n",
       "  0.4833  0.2032\n",
       "  0.2032  1.0233\n",
       " [torch.FloatTensor of size 2x2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 2\n",
    "output_size = d * (d + 3) / 2\n",
    "output = Variable(torch.randn(output_size), requires_grad=True)\n",
    "\n",
    "means = output[:d]\n",
    "variances = output[d:2*d].exp()\n",
    "correlations = output[2*d:].tanh()\n",
    "\n",
    "# Constant tensor of upper off-diagonal indices\n",
    "offdiag_idx = torch.ones(d, d).triu(1).nonzero().t()\n",
    "\n",
    "# Populate the covariance matrix initially with sqrt(vi*vj)\n",
    "cov_matrix = torch.mm(variances[:, None], variances[None, :]).sqrt()\n",
    "\n",
    "# Scale the off-diagonal terms with the correlation to get covariance\n",
    "cov_matrix[offdiag_idx[0], offdiag_idx[1]] = cov_matrix[offdiag_idx[0], offdiag_idx[1]] * correlations\n",
    "cov_matrix[offdiag_idx[1], offdiag_idx[0]] = cov_matrix[offdiag_idx[1], offdiag_idx[0]] * correlations\n",
    "\n",
    "means, variances, correlations, cov_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Matrix of variances and covariance factors\n",
    "var_matrix = torch.mm(variances[:, None], variances[None, :]).sqrt()\n",
    "var_matrix\n",
    "\n",
    "cor_matrix = Variable(torch.zeros(d, d), requires_grad=True).clone()\n",
    "cor_matrix[offdiag_idx[0], offdiag_idx[1]] = correlations\n",
    "cor_matrix[offdiag_idx[1], offdiag_idx[0]] = correlations\n",
    "cor_matrix\n",
    "\n",
    "# Construct the final covariance matrix!\n",
    "cov_matrix = (cor_matrix + Variable(torch.eye(d))) * var_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop gaussian log likelihood loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.4388\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target value\n",
    "y = Variable(torch.randn(d))\n",
    "\n",
    "# Residual term\n",
    "error = y - means\n",
    "res_term = error.dot(torch.mv(cov_matrix.inverse(), error))\n",
    "\n",
    "# Log determinant term\n",
    "det_term = cov_log_determinant(cov_matrix)\n",
    "\n",
    "# Total loss\n",
    "lgl_loss = res_term + det_term\n",
    "lgl_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extend it to work on batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's implement specifically for d=2 for simplicity\n",
    "d = 2\n",
    "batch_size = 2\n",
    "output_size = d * (d + 3) / 2\n",
    "output = Variable(torch.randn(batch_size, output_size), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " -0.0125 -1.3630\n",
       "  1.9493  0.8524\n",
       " [torch.FloatTensor of size 2x2], Variable containing:\n",
       "  0.6606  0.2098\n",
       "  0.4833  1.9598\n",
       " [torch.FloatTensor of size 2x2], Variable containing:\n",
       " -0.2505\n",
       "  0.4468\n",
       " [torch.FloatTensor of size 2], Variable containing:\n",
       " (0 ,.,.) = \n",
       "   0.6606 -0.0932\n",
       "  -0.0932  0.2098\n",
       " \n",
       " (1 ,.,.) = \n",
       "   0.4833  0.4348\n",
       "   0.4348  1.9598\n",
       " [torch.FloatTensor of size 2x2x2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = output[:, :2]\n",
    "variances = output[:, 2:4].exp()\n",
    "correlations = output[:, 4].tanh()\n",
    "\n",
    "cov_matrix = torch.bmm(variances[:, :, None], variances[:, None, :]).sqrt()\n",
    "cov_matrix[:, 0, 1] = cov_matrix[:, 0, 1] * correlations\n",
    "cov_matrix[:, 1, 0] = cov_matrix[:, 1, 0] * correlations\n",
    "\n",
    "means, variances, correlations, cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the loss\n",
    "\n",
    "I could just loop over the samples in the batch. It's not very parallelizable, though. Maybe if it's just in the loss it won't be too bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target value\n",
    "y = Variable(torch.randn(batch_size, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Residual error\n",
    "error = y - means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate each inverse separately\n",
    "inv_cov_matrix = torch.stack([cov.inverse() for cov in cov_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 2]), torch.Size([2, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_cov_matrix.size(), error.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 14.6666\n",
       "  4.3070\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Cov^{-1} * error as a batch matrix multiply\n",
    "res_right = torch.bmm(inv_cov_matrix, error.unsqueeze(-1)).squeeze(-1)\n",
    "# Expand dimensions to perform dot products as batch matrix multiply\n",
    "res_term = torch.bmm(error[:,None,:], res_right[:,:,None]).squeeze()\n",
    "res_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.0412\n",
       "-0.2768\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_chols = torch.stack([Cholesky.apply(cov).diag() for cov in cov_matrix])\n",
    "log_det = diag_chols.log().sum(1) * 2\n",
    "log_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 17.3911\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total loss\n",
    "lgl_loss = (res_term + det_term).sum()\n",
    "lgl_loss"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
